- Pipline pickling (replace/restore function)

- PickleableException (transmission of stacks): Stacks aren't
  reported, but errors are now transmissible.

- remove_cr_lf

- clone (pickling)

- scp, ssh via spawning. Is there a native way to do this?

- print_stack

- Forks

- Write OshArgParser.exit to avoid SystemExit on argparse error.

- CommandKiller shouldn't print stack. (dev only),
  default_exception_handler too.

- Get rid of default and related exception handlers? (See ideas.txt on replacing stderr.)

----------------------------------------------------------------------

yield is more expensive than send/receive. See
experiments/sendreceive_vs_yield.py.

----------------------------------------------------------------------

Instead of stdout, stderr: One output stream. stdout -> stream as
is. stderr -> Error objects.

KillAndResumeException does some things right. Raises an exception and
allows for continuation of the command. What's wrong: Prints to
stderr, which isn't all that helpful. Really want to pass the error
along through ops until it hopefully reaches an out. So send/receive
needs to check for errors and pass them through.

UPDATE:

OK, now OshErrors show up in the stream:

    > gen 3 -1 | map (x: 5 / x)
    -5.0
    map(x: 5 / x) failed on (0,): division by zero
    5.0

The middle line of output is an OshError object. This enables testing
for errors, filtering them out, redirecting them to a file, etc.

But if the error happens remotely:

    > @jao [ gen 3 -1 | map (x: 5 / x) ]
    (localhost, -5.0)
    (localhost, map(x: 5 / x) failed on (0,): division by zero)
    (localhost, 5.0)

The error is now embedded and harder to test for. 

Idea:

- OshError is always embedded, typically in a 1-tuple.

- Testing for error looks for an OshError anywhere inside the tuple.

----------------------------------------------------------------------

- ctrl-c handling

----------------------------------------------------------------------\

namespace

----------------------------------------------------------------------

More modern string formatting

----------------------------------------------------------------------

Symlink: Include referenced file

----------------------------------------------------------------------

~ expansion

----------------------------------------------------------------------

- cd with no args.

----------------------------------------------------------------------

- What are the rules for ls & symbolic links? Need some equivalent to
  bash "ls -ld"?

----------------------------------------------------------------------

- File comparisons need to account for display_base.

----------------------------------------------------------------------

- Tab completion for ops should tailor the list to whether the op
  being completed is first in the pipline, or downstream. E.g., don't
  show select as a first op.


----------------------------------------------------------------------

.marcel.py has to use env vars as VAR.value. Any way to get rid of
.value? Or at least import it syntactically? E.g. $(VAR) wouldn't be
bad, but $ is not legal in an identifier.

EASY: Just update the namespace directly, when env vars are updated!
Also need to clear all Function.functions, so that they get
regenerated with the updated namespace. (Is this right? Need to
experiment.)

----------------------------------------------------------------------

File object uses os.stat/lstat. When a file is transmitted, stat
result should be cached in the file, and then not overridden on the
receving side. So the File needs to have a field indicating if it has
been transmitted/reconstructed.

----------------------------------------------------------------------

- ^emacs works -- a new window running GUI emacs is created. So does
  ^emacs -nw, doing exactly the right thing (non-graphical, in current
  terminal). But ^vi does not. Nothing appears to happen. But vi is
  listening for input, so :q exits. stderr complains about not being a
  terminal, but this isn't visible. Vi DOES work if subprocess.run
  omits stdout=PIPE and stderr=PIPE.

----------------------------------------------------------------------

- .marcel.py might want a cluster named jao and a terminal profile
  named jao. Need separate namespaces for these things.

----------------------------------------------------------------------

- pushd/popd

----------------------------------------------------------------------

Get rid of "from ... import ..."

----------------------------------------------------------------------

Tab completion for flags of executables.

----------------------------------------------------------------------

Clean up parser to prepare for more general handling of pipelines:

- @fork [ ... ] currently:

    - fork_start and fork_spec grammar states and actions.
    
    - InProgress has fork_spec field.

    - finish_pipeline assumes that a fork op is being completed.

- Generalize:

    + Treat fork like any other op. START action creates an op just
      like for a string. Don't need START_FORK and FORK_SPEC states.

    + Choice between LocalFork and RemoteFork can't be done by
      create_fork.  Keep choice inside Fork op, delegate instead of
      inherit.

    + Fork has to be a more standard op. The only thing special about it
      is the syntax used to invoke it, @.

    + create_op also has some op-specific logic, distinguishing op
      from executable, and using the bash operator in the latter case.

    + finish_pipeline: Remove special handling of fork op. The
      pipeline just goes into op.args.


----------------------------------------------------------------------

cd doesn't work because it's running in a Process. Doesn't affect the
env visible to the main process.

----------------------------------------------------------------------

red needs a counting primitive.

    ... | f (x: 1) | red +

is too verbose and arcane for something so common. Something like:

   ... | red #

Except that # is typically a shell comment marker.

Define a "count" function?

----------------------------------------------------------------------

- Markup 2.0.

- Modify docs to use the markup 2.0.

- Get rid of define_color, define_prompt, define_continuation_prompt.

- Merge env and config. Env vars are just top-level symbols in the
  namespace.



Env, config, global_state:

main: 

    - self.env = Environment(config_path)

    - self.global_state = GlobalState(env)

    - Main loop calls self.env.prompts() which mostly delegates to config.

    - Execution passes self.global_state to parser.

    - Main defines update_env_vars, which is used by JobControl to update
      vars modified by Job running in another process. These call env.setvar
      which then ends up in config.

env:

    - Reads parts of environment (user, host, homedir, current dir)

    - __init__ gets config_path from caller (main)

    - Sets env vars, self._vars

    - Create config and store in self._config.

    - self._color_scheme = color scheme from config.

    - Implements current dir operations: cd, pushd, popd, dirs,
      pwd. Dir stack is maintained in config, as a var. Problem with
      this approach: User can modify it directly, unless setvar() 
      checks for it. Same with PWD, which works in bash, but leads to
      weird results, e.g.

            jao@cheese:~$ PWD=/tmp
            jao@cheese:/tmp$ pwd
            /home/jao

    - Access to cluster, config, color_scheme, all of which reside in config.

config:

    - Has self._env_vars, prompt, continuation prompt.

    - self.function_namesspace is the namespace in which commands run. Defined by
      executing .marcel.py, in read_config. 

    - read_config puts Color, PROMPT, PROMPT_CONTINUATION, COLOR_SCHEME, define_cluster
      in globals(), passes to exec(.marcel.py). Then, COLOR_SCHEMA is put in function namespace.
      Should probably put everything there.

GlobalState:

    - Attached to parser, pipelines, available everywhere as a result.

    - Has env, edited_command, op_modules.

    - Provides function_namespace via delegation.


Cleanup:

+ Merge Environment and Configuration. Get rid of Configuration.

+ Put directory logic into its own class.

+ Replace GlobalState by Environment. Move GlobalState fields into
  Environment.

+ After execing .marcel.py, copy locals into globals. globals replaces
  function_namespace.

+ Move VERSION from env to an environment variable, MARCEL_VERSION.

-----------------------------------------------------------------------


Why is define_colors necessary? Just assign Colors to variables, which 
can then be referenced in define_color_schema, and define_prompt?

similarly, get rid of define_prompt, define_continuation_prompt.

Unify environment and config: Make the namespace the repository of env vars.


Need arbitrary colors in markup, e.g. so that colorized prompt can be
described.

----------------------------------------------------------------------

Need to handle {} chars in markup. See help_operator.py.

----------------------------------------------------------------------


Turn off color scheme for API

----------------------------------------------------------------------

API execution

- run(pipeline): Append Out() if not present, same as console.

- first(pipeline): 

    - Return the first result (or Error). 
    - Should Error raise exception (by default)?

- gather(pipeline):

    - Return all results in a list.

    - Options for Errors in output, errors in separate list, handler

- for x in pipeline: ...

    - What about Errors?

    - pipeline is terminted with gather, by default, returning errors
      in list. Allow for explicit gather() to control options.

----------------------------------------------------------------------

Need an api version of test_ops.
- Test run, gather, only

----------------------------------------------------------------------

Get rid of op.doc functions

----------------------------------------------------------------------

Can't rely on argparse type=... function to check inputs. Doesn't work
for API. Move checking to setup1().

----------------------------------------------------------------------

API: What to do about error handling, when there is no out operator
present? It would be nice to get the exit code too. What is the exit
code for a pipeline in bash?

----------------------------------------------------------------------

Turning off color scheme involves using a ColorScheme will all entries
set to None. Awkward for file extensions. Instead, do this by removing
the COLOR_SCHEME variable.

----------------------------------------------------------------------

Do __init__.py files need to specify __all__?

No.

----------------------------------------------------------------------

Now that there is File.readlines, expand no longer has to have special
handling for files.

----------------------------------------------------------------------

There is a lot of Op and Pipeline copying in the core __or__
functions. Try to minimize it. 

API performance is now terrible, (per profiler), due to the copying.

......................................................................

a = ls ...
b = a | map ... 
c = b | select ...

a: Create op, no copying
b: Copy a and the op
c: Copy b and the op

The problem is that the pipeline is mutable, and to protect the state
of each var's pipeline, a copy has to be made.

Alternative: 

- Build up immutable structures

- Create pipeline at execution time.

- Creating ops pre-execution is fine, but the pipelines have to be
  built later.


op1 | op2 -> Node(op1, op2)

node | op -> Node(node, op)

Example above:

a = ls
b = Node(ls, map)
c = Node(Node(ls, map), select)

Reassigning a var does not change anything previous computed form it.


a = ls | map
b = foo | bar
c = abc | def

a | b | c

equivalent to ls | map | foo | bar | abc | def. Don't need RunPipeline
to maintain the nested structure.


Remote(self, env, pipeline): needs work

----------------------------------------------------------------------

Need a way to dump the entire environment.
 
----------------------------------------------------------------------

fork() can be simplified by using Pipelineable.

----------------------------------------------------------------------

history command doesn't go into history, so this is missed:

    history | select (h: 'join' in h.command)

Can't recall it.

----------------------------------------------------------------------

Multiline command actually works without \. But then it doesn't get recalled
correctly on startup. 

- Allow omission of \
- But add it if missing, at least for stored history.


----------------------------------------------------------------------

x > y
x >> y

should be able to copy/append x to y. 

----------------------------------------------------------------------

- Licensing header


----------------------------------------------------------------------

File objects

- File navigation (parent, children, ...). Sort of works. Should
  _getattr() wrap a path (if delegation returns one) into a File?


----------------------------------------------------------------------

For tecmint article:

+ Run scripts, suppressing prompt

+ Generate minimal .marcel.py.

- Bugs:

    + 75
    + 76


----------------------------------------------------------------------

Need to suppress prompts if running piped-in script.

----------------------------------------------------------------------

Set ops.

----------------------------------------------------------------------

- Should the name of map be changed? f as in osh? apply? map doesn't
  really make sense when used as a generator. Could have gen handle
  this case through a function argument mutually exclusive with other
  args. So "gen 5" works like it always had, but "gen (5)" generates a
  5?!

----------------------------------------------------------------------

- Documentation of Errors. Revisit error handling: Since errors are
  now handled by Op, why do they need to be sent down the pipeline? We
  are no longer relying on out to print them. farcel's handler could
  pickle them immediately, (i.e., it doesn't have to rely on the error
  reaching the end of the pipeline).

----------------------------------------------------------------------

- shlex.quote() usage, and wildcards need to be
  reconsidered. Automatically quoting everything is wrong, (bug 38). So
  maybe the problem is that bash is wrong. Need to preserve the bash
  args exactly as written, quotes included, and pass it all to Popen. As
  things stand, we lose the quotes during parsing, and then add them
  back unconditionally.
  
  Globbing is tricky because it then requires great care to quote and
  escape properly, e.g. a\ b*, 'a b'*, 'a b*', (the first two are the
  same, the last has no wildcard).


----------------------------------------------------------------------

Should expand operate on filenames? Might be better to have a separate
command for that, e.g. cat.


----------------------------------------------------------------------

# as comment

----------------------------------------------------------------------

Get rid of argparse in main.

----------------------------------------------------------------------

squish is ALWAYS needed following window. Make this unnecessary.

----------------------------------------------------------------------

args -a|--all: gather everything from input stream. E.g.

    ls ... | args [files: cp (' '.join(files)) dest_dir]

Might want a builtin function for quoting a list of Files for a bash command, e.g. quote_files()

    ls ... | args [files: cp (quote_files(files)) dest_dir]

----------------------------------------------------------------------

ls -fr | ... | cp ???

Would like to copy all the incoming files somewhere. No way to do this
natively in marcel!

- Need a cp operator?

- It is doable with help from xargs: ...| xargs cp -t DEST

It would also be nice to be able to pipe files and directories into a removal operator.

----------------------------------------------------------------------

ls args of type pathlib.Path should work.

----------------------------------------------------------------------

env is hard to read. Make it easier:

- flags to obtain:

    - builtin symbols
    - symbols defined in config file
    - symbols defined via interaction 

----------------------------------------------------------------------

sql option to suppress printing of update counts.

----------------------------------------------------------------------

Allow read op to specify files as args?

----------------------------------------------------------------------

Cleanup setup_1/setup_2/set_env.

----------------------------------------------------------------------

Allow omitting of map in all contexts? E.g.

      ls | (f: f.size)

It already works! It's not a bug, it's a feature! As it turns out.

----------------------------------------------------------------------

File constructor is expensive. Not sure about pathlib.Path(), but
path.relative_to() must cost something. ls might be faster if this
were optimized. Measure & fix.

Profiling:

    import os
    import time
    
    from marcel.api import *
    
    start = time.time()
    run(ls('/home/jao/git', recursive=True, file=True) | select(lambda f: False))
    stop = time.time()
    msec = (stop - start) * 1000
    print(f'{msec} msec')

1808 msec
1790
1824
----
average: 1807

- Optimize File.__init__

    - store base, compute compact_path lazily

1417
1399
1403
----
average: 1406

- Optimize ls.send_path. 

    - path methods is_symlink, is_file, is_dir each involve a stat call.

1057
1082
1076
----
average: 1072


----------------------------------------------------------------------

Review pickler. Probably too complicated, may not be needed.

- Can Environment.remotify do a shallow copy?

----------------------------------------------------------------------

Start this command: ls -r ~ > ./x, and put it in the background.

Monitoring progress is problematic.

- Checking the file size works.

- Running tail occasionally: It executes but
  shouldn't. PickleFile.reader() asserts that there are no writers,
  and that's not firing.

- Ignoring that, tail usually fails: _pickle.UnpicklingError: pickle
  data was truncated. I'm guessing that dill.dump() flushes to disk on
  buffer boundaries, not object boundaries, so reading a file while
  it's being written can't work.

BUT: 

- pickle seems to avoid this problem. Or at least it's much rarer.

- pickle is also a lot faster, 20x. See experiments/dill_vs_pickle.py

----------------------------------------------------------------------

history:

Add flags:

    -n: n is int, list last n

    -c x: list items containg x


----------------------------------------------------------------------

Honestly, the marcel equivalent to grep is kind of a pain.

    grep foo *.txt

->

    read -l *.txt | select (file, line: 'foo' in line) | map (file, line: file)

Can grep (at least, this simplified usage) be expressed as a pipeline?

grep = [pattern, files: read -l (files) | select (f, l: pattern in l) | map (f, l: f) | unique]

Yes! except that "grep" is understood to be an executable. Need to
work out order of resolution (e.g., want vars before executables).


----------------------------------------------------------------------

ls gets COLOR_SCHEME on each File:

M-0.11.0 jao@cheese:~/git/marcel/marcel$ ls | ext py 
getvar 139884242926800: PWD -> 139884242937296
getvar 139884242926800: ext -> 139884241896976
runpipeline.setup_1 ext: 139884241896976 [e: select(lambda f: f.suffix == '.' + e)]
runpipeline.setup_1 pipeline env: <marcel.env.Environment object at 0x7f39569bfcd0>
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-r--r--   jao    jao         652   2020 May 10 15:41:11   __init__.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao        7591   2020 Oct 08 14:28:17   api.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao       18875   2020 Oct 05 12:02:02   argsparser.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao        1356   2020 Oct 09 11:24:21   builtin.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao       12925   2020 Oct 11 13:22:27   core.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao       11985   2020 Oct 11 13:26:13   env.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-r--r--   jao    jao        4506   2020 Aug 21 09:20:16   exception.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472

----------------------------------------------------------------------

File.unlink()

----------------------------------------------------------------------

Replace /proc usage by OS calls?

See psutil

----------------------------------------------------------------------

Make Bash.INTERACTIVE_EXECUTABLES an environment variable, so that it
can be customized by the user.

----------------------------------------------------------------------

Red:

- Need a red function for creating a list. + isn't a good choice, since it
  already does expected things for numbers and strings. 

- Can squish be eliminated in favor of some variation of red? 

Could at least generalize similar to expand. E.g. squish 1 would take
a sequence in position 1 and squish just that. So

(1, [[1]])
(2, [[2], [2]])
(3, [[3], [3], [3]])

 ->

(1, [1])
(2, [2, 2])
(3, [3, 3, 3])

----------------------------------------------------------------------

Merge Env and Main? Or maybe make Main the thing that is available
globally?

----------------------------------------------------------------------

head/tail options to SKIP first N/last N lines.

----------------------------------------------------------------------

env options to print one var, or to find a var. Autocomplete.

----------------------------------------------------------------------

ANSI color codes not working on CentOS (Nasuni VM):

https://stackoverflow.com/questions/64791428/why-are-ansi-escape-codes-not-displaying-properly/64846705#64846705

----------------------------------------------------------------------

Bash output gets buffered until EOF. Terrible for monitoring progress.


----------------------------------------------------------------------

Line numbers?

This one keeps coming up. Handling the first element of a stream
differently from the rest. I wrote this script to sum up some, but not
all columns of a csv file (from nasuni consulting):

    #!/usr/bin/python3
    
    import sys
    
    from marcel.api import *
    
    
    def keep(acc, x):
        return x
    
    
    run(
        read(sys.argv[1], csv=True) |
        head(1) |
        out(file=sys.argv[2],csv=True)
    )
    run(
        read(sys.argv[1], csv=True) |
        head(-1) |
        map(lambda t, m, v, pk, d, h, rl, ul: (float(t),
                                               int(m),
                                               int(v) * 5000000000,
                                               int(pk),
                                               int(d),
                                               int(h),
                                               int(rl),
                                               int(ul))) |
        red(keep, r_plus, keep, r_plus, r_plus, r_plus, r_plus, r_plus, incremental=True) |
        map(lambda *x: x[len(x)//2:]) |
        out(append=sys.argv[2], csv=True)
    )

This reads the input file twice, once for the header (head(1)), once
for the data (head(-1)). It would be nice to do everything in one pass, e.g.

    read(sys.argv[1], csv=True) |
    ifelse ???first line??? [out(file=sys.argv[2],csv=True)] | 
    red ...

How should the predicate be expressed?

- Could write a predicate on the input line. In this case, detecting
  the first (headings) line of a csv file. But hard to do it reliably,
  and its different for every application.

- Function or variable yielding row#?

- Each op could have a counter.

Profiling 5 runs of: run(gen(1000000) | map(lambda x: -x) | select(lambda x: False))
Measured msec.

Without counter:       1963 1987 1884
With counter:          2423 2352 2566
_env instead of env(): 2096 2229 2195
optimized*:            2290 2199 2239
                       2303 2260 2181

The counter is REALLY EXPENSIVE!

* Micro-optimization of receive_input

----------------------------------------------------------------------

Import bash env

----------------------------------------------------------------------

timer: allow interval to be an int or real (#sec)

----------------------------------------------------------------------

todo: fork doc describes remote execution. Doesn't discuss @int, or
@sequence. Does @sequence even work? Non-remote versions are kind of
useless without more interesting kinds of sequences, and a way for
each copy of the pipeline to access the label.

----------------------------------------------------------------------

env -d: Delete var

----------------------------------------------------------------------

Move history to xdg directory

----------------------------------------------------------------------

Labeled columns for csv. Allow first row to specify column names, and
use these to form typed columns.

----------------------------------------------------------------------

union, intersect, join should allow for multiple inputs.

(Not join: join --keep can produce ambiguous results with multiple
inputs).

----------------------------------------------------------------------

"marcel < script.m" runs a script of marcel commands. How to pipe
input to it?

----------------------------------------------------------------------

Binding of vars in pipelines

e.g. x = (| p |)

- Should it be assumed that p is a pipeline var? 

- OK to depend on the value?

- What if p is rebound? Not to a pipeline? Does x bind p's name? p's value?

Resolved as bug 202


----------------------------------------------------------------------

Don't need both the delete op and env -d.

----------------------------------------------------------------------

Instead of difference --filter, and intersect --filter, should there
be a filter command?

Could be more general, e.g.

- Use a function to extract comparison fields of incoming stream.

Or add that function as the value of --filter?

......................................................................

filter op:

filter [-k|--keep] [-d|--discard] [KEY] PIPELINE

-k, --keep         Keep input tuples that match any tuple from the PIPELINE.

-d, --discard      Keep input tuples that do not match any tuple from the PIPELINE.

KEY                Computes the comparison key from a left tuple.

PIPELINE           Source of right tuples.

Filter the input stream based on the contents of the PIPELINE.

The input stream will be referred to as the left input), and the
stream from the PIPELINE will be referred to as the right input.

Tuples from the left input are passed to the output stream or not,
depending on a comparison between that tuple and the right input. For
each left input tuple:

- Compute the comparison key by applying the KEY function to the left
  tuple. If KEY is not provided, then the key is the entire tuple.

- If --keep is specified, and the key matches any tuple from the right
  input stream, then write the left tuple to the output stream.

- If --discard is specified, and the key does not match any tuple from
  the right input stream, then write the left tuple to the output
  stream.

In other words, --keep is similar to set intersection, while --discard
is similar to set difference.

If neither --keep nor --discard are specified, then --keep is assumed.

----------------------------------------------------------------------

Clean up stderr output

M 0.18.5 jao@loon ~$ bash -c "cat $(which marcel)"
Error: ['/bin/bash: - : invalid option']
Error: ['Usage:\t/bin/bash [GNU long option] [option] ...']
Error: ['\t/bin/bash [GNU long option] [option] script-file ...']
Error: ['GNU long options:']
Error: ['\t--debug']
Error: ['\t--debugger']
Error: ['\t--dump-po-strings']
Error: ['\t--dump-strings']
Error: ['\t--help']
Error: ['\t--init-file']
Error: ['\t--login']
Error: ['\t--noediting']
Error: ['\t--noprofile']
Error: ['\t--norc']
Error: ['\t--posix']
Error: ['\t--pretty-print']
Error: ['\t--rcfile']
Error: ['\t--restricted']
Error: ['\t--verbose']
Error: ['\t--version']
Error: ['Shell options:']
Error: ['\t-ilrsD or -c command or -O shopt_option\t\t(invocation only)']
Error: ['\t-abefhkmnptuvxBCHP or -o option']

----------------------------------------------------------------------

Need an exit command, which is run by Ctrl-D.

----------------------------------------------------------------------

Resurrect SQL

----------------------------------------------------------------------

Reduction to form a list is clunky. Need to enclose the items to be
gathered into lists before reduction with +.

    p = (| n: gen (int(n)) | (x: (x, [x]*x)) | expand 1

    p 5 | (x, y: (x, [y]) | red . +

Also, list growth is quadratic. Each reduction with + requires copying
of the list.

Could add a reduction function, gather:

    p 5 | red . gather

gather(x) -> x for non-list x.

def gather(acc, x):
    if acc is None:
        return [x]
    else:
        acc.append(x)
        return acc

This appends to an accumulating list instead of creating a new list
each time, so linear.


In reduction.py, r_concat does exactly this, so that red . concat works.

But the reduction function must be hardwired. Why not open it up?

----------------------------------------------------------------------

Have expand work on maps?

E.g. expand {'a': 1, 'b': 2} -> ('a', 1), ('b', 2)

----------------------------------------------------------------------

Have expand work on generators. There's TODO in expand. The problem is
recognizing a generator. Should include zips, but util.is_generator
doesn't do it.

----------------------------------------------------------------------

REALLY need a trace facility. 


----------------------------------------------------------------------

Args SendToParent class is probably more broadly useful. Any other op
relaying output in a similar way probably also needs to implement
receive_error (bug 247).

----------------------------------------------------------------------

Pipeline args should support optional values, e.g. the graph pipeline. 

Difficult:

- This isn't in a python context, so marcel is doing all the
  parsing. If we allowed for python syntax, we'd have to allow python
  expressions, support *args, **kwargs, /, etc. And pipeline scoping
  rules are non-pythonic, allowing for multiple scopes.

- But turning the whole pipeline into a python something doesn't
  really work. It would have to span the entire pipeline inside (|
  ... |).

How about a special case: If a parameterized pipeline has n params,
then allow for invocation with <= n args. Bind left to right and pad
with null.

----------------------------------------------------------------------

WS: Add idea of a base directory. This will enable prompt dirs to be
shorter -- just show the part relative to the base.

----------------------------------------------------------------------

Pipelines have a lot of (x, y, z: ...) | (x, y, z: ...).

It would be nice to have named tuples. E.g.

   (x, y, z: magic_happens_here)

yields objects with attributes x, y, z. Then ... | (x: x.m + x.y ...)

Or maybe a special version of map: ... | fx (x.m + x.y ...). But that
only works for map. E.g., select would still be "select(x: x.m ...)"

----------------------------------------------------------------------

Having a reservoirs directory in the same directory as named
workspaces is a bad idea. What if someone wants a directory named
"reservoirs"?

----------------------------------------------------------------------

Replace RUN_ON_STARTUP with function call, e.g. run('''...''')


----------------------------------------------------------------------

read -c should be able to specify types.

(cast op)

----------------------------------------------------------------------


----------------------------------------------------------------------

Buffering for constant width ls displays:

- The buffering affects all commands, since the buffering is in the
  write op. Not good. Completely messes up this, for example:

  timer 1

- Can the buffering be done inside of render_full? It's really only
  needed inside File.render_full. Maybe ps too.

- Another possibility: Instead of buffering, just keep track of widths
  and grow them as necessary. Will lead to some irregularities early
  in a listing, but buffering sucks.

----------------------------------------------------------------------

Migration test

----------------------------------------------------------------------

python zip is useful. Add an operator. Optional padding of shorter lists.

E.g.

input stream:

(1, 2, 3)
(4, 5, 6)

output:

(1, 4)
(2, 5)
(3, 6)


----------------------------------------------------------------------

Oops, [] is overloaded:

M-0.9.17 jao@cheese:/tmp/csv$ ls [b-f]*.csv
Operator ls: filenames must be a string: [runpipeline(b-f)]

But escaping works:

M-0.10.6 jao@cheese:~$ ls \[p-r\]*
-rw-rw-r--   jao    jao       36883   2020 Jul 05 19:23:14   passwords.txt
-rw-r--r--   jao    jao       13377   2019 Jan 20 12:43:37   reality_distortion_field.md
-rw-rw-r--   jao    jao        2415   2019 Oct 06 23:13:49   reload.txt

----------------------------------------------------------------------

Distinct color for broken symlink.

----------------------------------------------------------------------

cat = [ map (f: (f, f.readlines())) | expand 1 ]
(cat)

prints:

    pipeline(map(f: (f, f.readlines())) | expand(1))

It would be nice to have the original source.

----------------------------------------------------------------------

Does util need both of these?

def is_sequence(x):
    return type(x) is not str and isinstance(x, collections.abc.Sequence)


def is_sequence_except_string(x):
    t = type(x)
    return t is tuple or t is list

----------------------------------------------------------------------

Need a something to completely wipe out a workspace from the command
line. Or maybe on creation, when detecting a previously partially
cleaned up workspace. 
